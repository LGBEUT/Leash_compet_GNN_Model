{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8aadb-e3e9-4a6a-ab40-1248041cedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contains various utility functions for PyTorch embedding teste set and predict. \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from torch_geometric.data import Data, DataLoader as PyGDataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_scatter import scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import duckdb\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "\n",
    "\n",
    "print('import ok!')\n",
    "\n",
    "\n",
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Running on:', device)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "DEFAULT_BATCH_SIZE = 128\n",
    "DEFAULT_TEST_PATH = '/user1/icmub/lg361770/Calculs/IA/leash_compet/test.csv'\n",
    "\n",
    "# Download data from a specified path\n",
    "def download_data(path):\n",
    "    con = duckdb.connect()\n",
    "    try:\n",
    "        # Utilisation de la methode format pour eviter les f-strings\n",
    "        sql_query = \"(SELECT * FROM read_csv('{}'))\".format(path)\n",
    "        df = con.query(sql_query).df()\n",
    "    except Exception as e:\n",
    "        # Utilisation de la concatenation classique pour la gestion des erreurs\n",
    "        print(\"An error occurred: \" + str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        con.close()\n",
    "    return df\n",
    "\n",
    "############## Preprocess the data\n",
    "def preprocessing(df):\n",
    "    data_test = [smile.replace('[Dy]', 'C') for smile in df[\"molecule_smiles\"]]\n",
    "    Id = df[\"id\"]\n",
    "    return data_test, Id\n",
    "\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set, allow_unk=False):\n",
    "\tif x not in allowable_set:\n",
    "\t\tif allow_unk:\n",
    "\t\t\tx = allowable_set[-1]\n",
    "\t\telse:\n",
    "\t\t\traise Exception(f'input {x} not in allowable set{allowable_set}!!!')\n",
    "\treturn list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "#Get features of an atom (one-hot encoding:)\n",
    "'''\n",
    "\t1.atom element: 44+1 dimensions    \n",
    "\t2.the atom's hybridization: 5 dimensions\n",
    "\t3.degree of atom: 6 dimensions                        \n",
    "\t4.total number of H bound to atom: 6 dimensions\n",
    "\t5.number of implicit H bound to atom: 6 dimensions    \n",
    "\t6.whether the atom is on ring: 1 dimension\n",
    "\t7.whether the atom is aromatic: 1 dimension           \n",
    "\tTotal: 70 dimensions\n",
    "'''\n",
    "\n",
    "ATOM_SYMBOL = [\n",
    "\t'C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg',\n",
    "\t'Na', 'Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl',\n",
    "\t'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H',\n",
    "\t'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n",
    "\t'Pt', 'Hg', 'Pb', 'Dy',\n",
    "\t#'Unknown'\n",
    "]\n",
    "#print('ATOM_SYMBOL', len(ATOM_SYMBOL))44\n",
    "HYBRIDIZATION_TYPE = [\n",
    "\tChem.rdchem.HybridizationType.S,\n",
    "\tChem.rdchem.HybridizationType.SP,\n",
    "\tChem.rdchem.HybridizationType.SP2,\n",
    "\tChem.rdchem.HybridizationType.SP3,\n",
    "\tChem.rdchem.HybridizationType.SP3D\n",
    "]\n",
    "\n",
    "def get_atom_feature(atom):\n",
    "\tfeature = (\n",
    "\t\t one_of_k_encoding(atom.GetSymbol(), ATOM_SYMBOL)\n",
    "\t   + one_of_k_encoding(atom.GetHybridization(), HYBRIDIZATION_TYPE)\n",
    "\t   + one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5])\n",
    "\t   + one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5])\n",
    "\t   + one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5])\n",
    "\t   + [atom.IsInRing()]\n",
    "\t   + [atom.GetIsAromatic()]\n",
    "\t)\n",
    "\t#feature = np.array(feature, dtype=np.uint8)\n",
    "\tfeature = np.packbits(feature)\n",
    "\treturn feature\n",
    "\n",
    "\n",
    "#Get features of an edge (one-hot encoding)\n",
    "'''\n",
    "\t1.single/double/triple/aromatic: 4 dimensions       \n",
    "\t2.the atom's hybridization: 1 dimensions\n",
    "\t3.whether the bond is on ring: 1 dimension          \n",
    "\tTotal: 6 dimensions\n",
    "'''\n",
    "\n",
    "def get_bond_feature(bond):\n",
    "\tbond_type = bond.GetBondType()\n",
    "\tfeature = [\n",
    "\t\tbond_type == Chem.rdchem.BondType.SINGLE,\n",
    "\t\tbond_type == Chem.rdchem.BondType.DOUBLE,\n",
    "\t\tbond_type == Chem.rdchem.BondType.TRIPLE,\n",
    "\t\tbond_type == Chem.rdchem.BondType.AROMATIC,\n",
    "\t\tbond.GetIsConjugated(),\n",
    "\t\tbond.IsInRing()\n",
    "\t]\n",
    "\t#feature = np.array(feature, dtype=np.uint8)\n",
    "\tfeature = np.packbits(feature)\n",
    "\treturn feature\n",
    "\n",
    "##############\n",
    "## def pour transformer des smiles en graph, uniquement pour le test set qui ne contient pas les Target \n",
    "def to_pyg_list(graph):\n",
    "\tL = len(graph)\n",
    "\tfor i in tqdm(range(L)):\n",
    "\t\tN, edge, node_feature, edge_feature, Id = graph[i]\n",
    "\t\tgraph[i] = Data(\n",
    "\t\t\tidx=i,\n",
    "\t\t\tedge_index=torch.from_numpy(edge.T).int(),\n",
    "\t\t\tx=torch.from_numpy(node_feature).byte(),\n",
    "\t\t\tedge_attr=torch.from_numpy(edge_feature).byte(),\n",
    "            Id=torch.tensor(Id, dtype=torch.int32) \n",
    "\t\t)\n",
    "\treturn graph\n",
    "\n",
    "\n",
    "def to_pyg_format(N,edge,node_feature,edge_feature, Id):\n",
    "\tgraph = Data(\n",
    "\t\tidx=-1,\n",
    "\t\tedge_index = torch.from_numpy(edge.T).int(),\n",
    "\t\tx          = torch.from_numpy(node_feature).byte(),\n",
    "\t\tedge_attr  = torch.from_numpy(edge_feature).byte(),\n",
    "        Id=torch.tensor(Id, dtype=torch.int32) \n",
    "\t)\n",
    "\treturn graph\n",
    "\n",
    "\n",
    "def smile_to_graph(args):\n",
    "\tsmiles, Id = args\n",
    "\tmol = Chem.MolFromSmiles(smiles)\n",
    "\tN = mol.GetNumAtoms()\n",
    "\tnode_feature = []\n",
    "\tedge_feature = []\n",
    "\tedge = []\n",
    "\tfor i in range(mol.GetNumAtoms()):\n",
    "\t\tatom_i = mol.GetAtomWithIdx(i)\n",
    "\t\tatom_i_features = get_atom_feature(atom_i)\n",
    "\t\tnode_feature.append(atom_i_features)\n",
    "\n",
    "\t\tfor j in range(mol.GetNumAtoms()):\n",
    "\t\t\tbond_ij = mol.GetBondBetweenAtoms(i, j)\n",
    "\t\t\tif bond_ij is not None:\n",
    "\t\t\t\tedge.append([i, j])\n",
    "\t\t\t\tbond_features_ij = get_bond_feature(bond_ij)\n",
    "\t\t\t\tedge_feature.append(bond_features_ij)\n",
    "\tnode_feature=np.stack(node_feature)\n",
    "\tedge_feature=np.stack(edge_feature)\n",
    "\tedge = np.array(edge,dtype=np.uint8)\n",
    "\treturn N,edge,node_feature,edge_feature, Id\n",
    "\n",
    "# Main function to get data in the required format\n",
    "def get_data_good_format(path, batch_size=32):\n",
    "    df = download_data(path)\n",
    "    smiles, Id = preprocessing(df)\n",
    "    # Transformer les Smiles en Graph \n",
    "    test_data = list(zip(smiles, Id))\n",
    "    num_test = len(test_data)\n",
    "    with Pool(NUM_WORKERS) as pool:\n",
    "        test_graphs = list(tqdm(pool.imap(smile_to_graph, test_data), total=num_test))\n",
    "    # Transformer les graph en objet Data Pytorch \n",
    "    test_graphs = to_pyg_list(test_graphs)\n",
    "    # Separe les donnees en ensembles dentrainement, de validation et de test\n",
    "    #train_val_graphs, test_graphs = train_test_split(train_graphs, test_size=0.1, random_state=42)\n",
    "    #train_graphs, val_graphs = train_test_split(train_val_graphs, test_size=0.1, random_state=42)\n",
    "    # Cree des DataLoader pour chaque ensemble de donnees\n",
    "    #train_loader = PyGDataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "    #val_loader = PyGDataLoader(val_graphs, batch_size=32, shuffle=False)\n",
    "    #test_loader = PyGDataLoader(test_graphs, batch_size=32, shuffle=False)\n",
    "    return test_graphs\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model using device-agnostic code.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# helper\n",
    "# torch version of np unpackbits\n",
    "#https://gist.github.com/vadimkantorov/30ea6d278bc492abf6ad328c6965613a\n",
    "\n",
    "def tensor_dim_slice(tensor, dim, dim_slice):\n",
    "\treturn tensor[(dim if dim >= 0 else dim + tensor.dim()) * (slice(None),) + (dim_slice,)]\n",
    "\n",
    "# @torch.jit.script\n",
    "def packshape(shape, dim: int = -1, mask: int = 0b00000001, dtype=torch.uint8, pack=True):\n",
    "\tdim = dim if dim >= 0 else dim + len(shape)\n",
    "\tbits, nibble = (\n",
    "\t\t8 if dtype is torch.uint8 else 16 if dtype is torch.int16 else 32 if dtype is torch.int32 else 64 if dtype is torch.int64 else 0), (\n",
    "\t\t1 if mask == 0b00000001 else 2 if mask == 0b00000011 else 4 if mask == 0b00001111 else 8 if mask == 0b11111111 else 0)\n",
    "\t# bits = torch.iinfo(dtype).bits # does not JIT compile\n",
    "\tassert nibble <= bits and bits % nibble == 0\n",
    "\tnibbles = bits // nibble\n",
    "\tshape = (shape[:dim] + (int(math.ceil(shape[dim] / nibbles)),) + shape[1 + dim:]) if pack else (\n",
    "\t\t\t\tshape[:dim] + (shape[dim] * nibbles,) + shape[1 + dim:])\n",
    "\treturn shape, nibbles, nibble\n",
    "\n",
    "# @torch.jit.script\n",
    "def F_unpackbits(tensor, dim: int = -1, mask: int = 0b00000001, shape=None, out=None, dtype=torch.uint8):\n",
    "\tdim = dim if dim >= 0 else dim + tensor.dim()\n",
    "\tshape_, nibbles, nibble = packshape(tensor.shape, dim=dim, mask=mask, dtype=tensor.dtype, pack=False)\n",
    "\tshape = shape if shape is not None else shape_\n",
    "\tout = out if out is not None else torch.empty(shape, device=tensor.device, dtype=dtype)\n",
    "\tassert out.shape == shape\n",
    "\n",
    "\tif shape[dim] % nibbles == 0:\n",
    "\t\tshift = torch.arange((nibbles - 1) * nibble, -1, -nibble, dtype=torch.uint8, device=tensor.device)\n",
    "\t\tshift = shift.view(nibbles, *((1,) * (tensor.dim() - dim - 1)))\n",
    "\t\treturn torch.bitwise_and((tensor.unsqueeze(1 + dim) >> shift).view_as(out), mask, out=out)\n",
    "\n",
    "\telse:\n",
    "\t\tfor i in range(nibbles):\n",
    "\t\t\tshift = nibble * i\n",
    "\t\t\tsliced_output = tensor_dim_slice(out, dim, slice(i, None, nibbles))\n",
    "\t\t\tsliced_input = tensor.narrow(dim, 0, sliced_output.shape[dim])\n",
    "\t\t\ttorch.bitwise_and(sliced_input >> shift, mask, out=sliced_output)\n",
    "\treturn out\n",
    "\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\t\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)\n",
    "\n",
    "\n",
    "# Setup hyperparameters\n",
    "PACK_NODE_DIM =9\n",
    "PACK_EDGE_DIM =1\n",
    "NODE_DIM =PACK_NODE_DIM*8\n",
    "EDGE_DIM =PACK_EDGE_DIM*8\n",
    "\n",
    "\n",
    "### Model \n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.mlp_msg = nn.Sequential(\n",
    "            nn.Linear(2 * emb_dim + edge_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n",
    "            nn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n",
    "        )\n",
    "        self.mlp_upd = nn.Sequential(\n",
    "            nn.Linear(2 * emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n",
    "            nn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr):\n",
    "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, edge_attr):\n",
    "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        return self.mlp_msg(msg)\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, h):\n",
    "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
    "        return self.mlp_upd(upd_out)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
    "\n",
    "\n",
    "class MPNNModel(nn.Module):\n",
    "    def __init__(self, num_layers=4, emb_dim=64, in_dim=9, edge_dim=4):\n",
    "        super().__init__()\n",
    "        self.lin_in = nn.Linear(in_dim, emb_dim)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "    def forward(self, batch):\n",
    "        h = self.lin_in(F_unpackbits(batch.x,-1).float())  \n",
    "\n",
    "        for conv in self.convs:\n",
    "            h = h + conv(h, batch.edge_index.long(), F_unpackbits(batch.edge_attr,-1).float())  # (n, d) -> (n, d)\n",
    "\n",
    "        h_graph = self.pool(h, batch.batch)  \n",
    "        return h_graph\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output_type = ['infer']\n",
    "        graph_dim = 96\n",
    "        self.smile_encoder = MPNNModel(\n",
    "            in_dim=NODE_DIM, edge_dim=EDGE_DIM, emb_dim=graph_dim, num_layers=4,\n",
    "        )\n",
    "        self.bind = nn.Sequential(\n",
    "            nn.Linear(graph_dim, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Passer le batch complet à smile_encoder\n",
    "        x = self.smile_encoder(batch)\n",
    "        bind = self.bind(x).squeeze(-1)\n",
    "\n",
    "        output = {}\n",
    "        if 'loss' in self.output_type:\n",
    "            target = batch.y  # Assurez-vous que target est dans batch.y\n",
    "            output['bce_loss'] = F.binary_cross_entropy_with_logits(bind, target.float())\n",
    "        if 'infer' in self.output_type:\n",
    "            probs = torch.sigmoid(bind)\n",
    "            output['bind'] = probs\n",
    "            output['preds'] = (probs >= 0.5).float()\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# Fonction pour charger le model, effectuer des prédictions, sauver les données\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    Id = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch)\n",
    "            predictions.append(output['bind'].cpu().numpy())\n",
    "            Id.extend(batch.Id.cpu().numpy())\n",
    "    return np.concatenate(predictions, axis=0), Id\n",
    "\n",
    "\n",
    "def save_predictions(predictions, ids, file_path):\n",
    "    output_df = pd.DataFrame({'id': ids, 'binds': predictions})\n",
    "    output_df.to_csv(file_path, index=False, header=True)\n",
    "    print(f\"Predictions saved to {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Define your main\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Train a GNN model on chemical data.\")\n",
    "    parser.add_argument('--test_path', type=str, default=DEFAULT_TEST_PATH, help='Path to the testing data CSV file.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    test_graphs = get_data_good_format(args.test_path, DEFAULT_BATCH_SIZE)\n",
    "    test_loader = PyGDataLoader(test_graphs, batch_size=DEFAULT_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = load_model(\"/user1/icmub/lg361770/Calculs/IA/leash_compet/data_15M/01_pytorch_GNN_15_000_000.pth\")\n",
    "    model.to(device).eval()\n",
    "\n",
    "    predictions, ids = predict(model, test_loader, device)\n",
    "    save_predictions(predictions, ids, 'output_15M.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "100jML",
   "language": "python",
   "name": "100jml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
